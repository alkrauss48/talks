Extracting, Loading,
and Transforming Data
Really Efficiently
with Laravel

By:
     Aaron Krauss

\@thecodeboss

@images/clevyr.png

This Talk Includes:

* A little bit of slides
* A lot of live demo

Note: You do not need
to know Laravel

ETL

Extract
Transform
Load

@images/etl-1.png

ETL Pipelines

Read / Write

Read = Read

Write =

* Insert
* Update
* Delete

@images/store-venn.png

Live Demo

Quick Intro into Laravel

The Data

@images/store-data.png

Our ETL Demo

Building a good ETL process

0. Pre-process the data

You want the data to end up
in a form that will make
the rest of your application
the most efficient.

1. Track metrics

2. Implement bulk queries

3. Keep logic flat

@images/store-venn.png

4. Write only as needed

Writes are more expensive
than Reads for two reasons:

* You're writing to a file
* You're breaking database cache

5. Implement database indexing

Done

Disclaimer

This isn't a perfect
ETL tool

Problems:

0. We're not paginating through table data

1. Ideally you could use a "modified_at" field
to limit reads

Takeaways:

0. Pre-process the data
1. Track metrics
2. Implement bulk queries
3. Keep logic flat
4. Write only as needed
5. Implement database indexing

Big Takeaway:

None of this only
applies to ETL!

You can use these
concepts in all of
your data-driven projects

Taking ETL to the next level

* Multi-granularity syncs

* Quick Sync
* Full Sync
* Overnight Sync

Examples of ETL
Processes I've Built

Pharmaceuticals Client

* Database Indexing
  * Took site load from 7s -> 1s

* Multi-granularity syncs
  * Quick - 10s
  * Full - 2m
  * Overnight - 2h

Oil & Gas Client

* Pre-process the data
* Implement bulk queries
* Keep logic flat

* Took site load from 18s -> 1s

How?

* Removed 500 queries from dashboard
* Removed procesing of data on client

Transformation Layer

thanks
* Aaron Krauss
* thecodeboss.dev

clevyr
clevyr.com

questions?
